{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7d35a",
   "metadata": {},
   "source": [
    "# Task: Find Most Similar Image Pairs for a Given Patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf13689",
   "metadata": {},
   "source": [
    "## Function 1: For each image, extract outline of tissue shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384d19d",
   "metadata": {},
   "source": [
    "### Motivation: Because we want to consider images from different stains, cannot use color or saturation to score similarity. Shape of tissue can be used to assess similarity accross stains. \n",
    "\n",
    "### Outcome: Return a dictionary of black-and-white images that contain the outline of the tissue. This format can be easily assessed for similarity of shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4909fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(folder_path, patient):\n",
    "    '''\n",
    "    folder_path: a path to a folder of all patients\n",
    "    patient: the patient id\n",
    "    '''\n",
    "    raw_images = {}\n",
    "    masked_images = {}\n",
    "\n",
    "    path = os.path.join(folder_path, patient)\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    all_files = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in images:\n",
    "        all_files.append(os.path.join(path, i))\n",
    "        all_labels.append(f\"{i}\")\n",
    "\n",
    "    print(f\"Total images: {len(all_files)}\")\n",
    "\n",
    "    names_concat = ''.join(images)\n",
    "\n",
    "    if len(all_files) < 3 or not all(['h&e' in names_concat, 'melan' in names_concat, 'sox10' in names_concat]):\n",
    "        return (None, None)\n",
    "\n",
    "    for idx, image_path in enumerate(all_files):\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Extracting image name\n",
    "        image_name = os.path.basename(all_labels[idx])\n",
    "\n",
    "        raw_images[image_name] = image\n",
    "\n",
    "        # Converting to grayscale\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Enhance contrast to improve contour accuracy\n",
    "        image_gray = cv2.equalizeHist(image_gray)\n",
    "\n",
    "        # Blurring the image to reduce noise\n",
    "        blurred = cv2.GaussianBlur(image_gray, (5, 5), 0)\n",
    "        \n",
    "        if 'melan' in image_name:\n",
    "            adaptive_thresholding = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 1)\n",
    "        elif 'sox10' in image_name:\n",
    "            adaptive_thresholding = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 13, 1)\n",
    "        else: \n",
    "            # Adaptive thresholding used to seperate foreground objects from the background\n",
    "            adaptive_thresholding = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                           cv2.THRESH_BINARY, 13, 1.8)\n",
    "\n",
    "        # Find initial contours and create binary mask\n",
    "        contours, _ = cv2.findContours(adaptive_thresholding, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        mask = np.zeros_like(adaptive_thresholding)\n",
    "        cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "        # Blurring to reduce noise\n",
    "        blurred_thresh = cv2.boxFilter(adaptive_thresholding, -1, (111, 111))\n",
    "        \n",
    "        # Create a mask for non-white areas directly from the binary image\n",
    "        lower_white = 200 \n",
    "        mask_binary = blurred_thresh > lower_white\n",
    "        \n",
    "        # Convert the boolean mask to a binary mask so it saves in the correct form\n",
    "        mask_binary_image = (mask_binary.astype(np.uint8) * 255)\n",
    "\n",
    "        # Save the new masked image to the dictionary\n",
    "        masked_images[image_name] = mask_binary_image\n",
    "\n",
    "    return raw_images, masked_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4a117",
   "metadata": {},
   "source": [
    "## Function 2: Calculates the similarity between two images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4db77",
   "metadata": {},
   "source": [
    "### Motivation: Create a helper function that takes two images of input using \"matchShape\" from OpenCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1fc19",
   "metadata": {},
   "source": [
    "### Outcome: Returns the similarity score between the two images, the lower the score, the more similar the images are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6930ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shape_similarity(image1, image2, image3):\n",
    "    # Invert images\n",
    "    image1 = cv2.bitwise_not(image1)\n",
    "    image2 = cv2.bitwise_not(image2)\n",
    "    image3 = cv2.bitwise_not(image3)\n",
    "\n",
    "    # Find contours\n",
    "    contours1, _ = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours2, _ = cv2.findContours(image2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours3, _ = cv2.findContours(image3, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    if contours1 and contours2 and contours3:\n",
    "        # Get the two largest contours for each set\n",
    "        sorted_contours1 = sorted(contours1, key=cv2.contourArea, reverse=True)[:2]\n",
    "        sorted_contours2 = sorted(contours2, key=cv2.contourArea, reverse=True)[:2]\n",
    "        sorted_contours3 = sorted(contours3, key=cv2.contourArea, reverse=True)[:2]\n",
    "\n",
    "        similarity_second1 = similarity_second2 = similarity_second3 = None\n",
    "        similarity_largest1 = similarity_largest2 = similarity_largest3 = 5\n",
    "        # Ensure there is at least one contour to compare\n",
    "        if len(sorted_contours1) > 0 and len(sorted_contours2) > 0:\n",
    "            similarity_largest1 = cv2.matchShapes(sorted_contours1[0], sorted_contours2[0], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "            if len(sorted_contours1) == 2 and len(sorted_contours2) == 2:\n",
    "                similarity_second1 = cv2.matchShapes(sorted_contours1[1], sorted_contours2[1], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "\n",
    "        if len(sorted_contours1) > 0 and len(sorted_contours3) > 0:\n",
    "            similarity_largest2 = cv2.matchShapes(sorted_contours1[0], sorted_contours3[0], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "            if len(sorted_contours1) == 2 and len(sorted_contours3) == 2:\n",
    "                similarity_second2 = cv2.matchShapes(sorted_contours1[1], sorted_contours3[1], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "\n",
    "        if len(sorted_contours2) > 0 and len(sorted_contours3) > 0:\n",
    "            similarity_largest3 = cv2.matchShapes(sorted_contours2[0], sorted_contours3[0], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "            if len(sorted_contours2) == 2 and len(sorted_contours3) == 2:\n",
    "                similarity_second3 = cv2.matchShapes(sorted_contours2[1], sorted_contours3[1], cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "\n",
    "        # Compute the final similarity\n",
    "        if all([similarity_second1, similarity_second2, similarity_second3]):\n",
    "            if (similarity_second1 + similarity_second2 + similarity_second3) <= 0.5:\n",
    "                return (((similarity_largest1 + similarity_largest2 + similarity_largest3) / 3) - 0.1)\n",
    "            \n",
    "        return ((similarity_largest1 + similarity_largest2 + similarity_largest3) / 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631ea67",
   "metadata": {},
   "source": [
    "## Function 3: Finds most similar images pairs for a given patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec715722",
   "metadata": {},
   "source": [
    "### Motivation: Calculate pair-wise similarity scores for all permulations of images for a paitient. Find most similar pair, and check to see if it falls within a minimum similarity threshold. If a pair that meets the threshold is found, recursively call the function on the remaining images until there are no pairs that meet minimum similarity.\n",
    "\n",
    "### Outcome: Return pairs of similar images for a given patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_similarities(raw_images, image_dict, matches = None):\n",
    "    if not matches:\n",
    "        matches = []\n",
    "        \n",
    "    similarity_scores = {}\n",
    "\n",
    "    # Generate all combinations of three images\n",
    "    for (key1, value1), (key2, value2), (key3, value3) in itertools.combinations(image_dict.items(), 3):\n",
    "        key_string = key1 + key2 + key3\n",
    "        # Checks if group contains all three stains\n",
    "        if 'h&e' in key_string and 'melan' in key_string and 'sox10' in key_string:\n",
    "            similarity = calculate_shape_similarity(value1, value2, value3)\n",
    "\n",
    "            if similarity is not None and similarity < 0.6 * 0.9 ** len(matches):\n",
    "                similarity_scores[(key1, key2, key3)] = similarity\n",
    "\n",
    "    if similarity_scores:\n",
    "        min_similarity = min(similarity_scores.values())\n",
    "        \n",
    "        # Find the corresponding image group\n",
    "        min_group = min(similarity_scores, key = similarity_scores.get)\n",
    "        \n",
    "        print(f\"Minimum similarity score: {min_similarity:.4f} between images: {min_group}\")\n",
    "        \n",
    "        matches.append({name:raw_images[name] for name in min_group})\n",
    "\n",
    "        for img in min_group:\n",
    "            del image_dict[img]\n",
    "            del raw_images[img]\n",
    "\n",
    "        return calculate_all_similarities(raw_images, image_dict, matches)\n",
    "        \n",
    "    if len(matches) > 0:\n",
    "        return matches\n",
    "    \n",
    "    print(\"No similar groups found - using alternative algorithm\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9c2a4",
   "metadata": {},
   "source": [
    "## Noah algorithm (modified by Aryaman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_contour(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # adaptive threshold to handle variations in color intensity\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # apply morphological operations to clean up image\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    morph = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # return the largest contour\n",
    "    return max(contours, key = cv2.contourArea)\n",
    "\n",
    "\n",
    "# compute shape similarity between two contours\n",
    "def shape_similarity(image1, image2):\n",
    "    # extract main contours\n",
    "    contour1 = extract_main_contour(image1)\n",
    "    contour2 = extract_main_contour(image2)\n",
    "    # matchShapes returns distance between shapes, take the inverse for similarity\n",
    "    return 1/cv2.matchShapes(contour1, contour2, cv2.CONTOURS_MATCH_I1, 0.0) if cv2.matchShapes(contour1, contour2, cv2.CONTOURS_MATCH_I1, 0.0) > 0 else np.inf\n",
    "\n",
    "def read(folder_path):\n",
    "    images = {}\n",
    "\n",
    "    for stain in os.listdir(folder_path):\n",
    "        images[stain] = cv2.imread(os.path.join(folder_path, stain))\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def find_groups(folder):\n",
    "    images = read(folder)\n",
    "    he_images, melan_images, sox10_images = {}, {}, {}\n",
    "    for i in images.items():\n",
    "        if 'h&e' in i[0]:\n",
    "            he_images[i[0]] = i[1]\n",
    "        elif 'melan' in i[0]:\n",
    "            melan_images[i[0]] = i[1]\n",
    "        elif 'sox10' in i[0]:\n",
    "            sox10_images[i[0]] = i[1]\n",
    "\n",
    "    return he_images, melan_images, sox10_images\n",
    "\n",
    "# Find all 3 way intersectionS from different sets\n",
    "def find_best_groups(he_images, melan_images, sox10_images):\n",
    "    best_groups = []\n",
    "    for i in he_images.items():\n",
    "        for j in melan_images.items():\n",
    "            for k in sox10_images.items():\n",
    "                similarity_score = shape_similarity(i[1], j[1]) + shape_similarity(i[1], k[1]) + shape_similarity(j[1], k[1])\n",
    "                best_groups.append((i[0], j[0], k[0], similarity_score))\n",
    "    best_groups.sort(key = lambda x: x[3], reverse = True)\n",
    "    return best_groups\n",
    "\n",
    "# Now remove all but the best groups\n",
    "# The way I will do this is to look at the 1st group, and remove all other groups that have the same image\n",
    "def remove_duplicates(groups):\n",
    "    new_groups = []\n",
    "    used_images = set()\n",
    "    for i in range(len(groups)):\n",
    "        if groups[i][0] in used_images or groups[i][1] in used_images or groups[i][2] in used_images:\n",
    "            continue\n",
    "        used_images.add(groups[i][0])\n",
    "        used_images.add(groups[i][1])\n",
    "        used_images.add(groups[i][2])\n",
    "        new_groups.append(groups[i])\n",
    "\n",
    "    return new_groups\n",
    "\n",
    "def make_new_image_groups(folder):\n",
    "    he_images, melan_images, sox10_images = find_groups(folder)\n",
    "    best_groups = find_best_groups(he_images, melan_images, sox10_images)\n",
    "    best_groups = remove_duplicates(best_groups)\n",
    "    \n",
    "    return best_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3e917",
   "metadata": {},
   "source": [
    "## Matching slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f8124e",
   "metadata": {},
   "source": [
    "#### First, use Faith's algorithm. If it does not identify any matches, then try Noah's algorihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f04b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_patients(folder_path):\n",
    "    patient_folders = os.listdir(folder_path)\n",
    "\n",
    "    for patient in patient_folders:\n",
    "        patient_path = os.path.join(folder_path, patient)\n",
    "        if os.path.isdir(patient_path):\n",
    "            raw_images, image_dict = extract_images(folder_path, patient)\n",
    "\n",
    "            if image_dict:\n",
    "                similarity_results = calculate_all_similarities(raw_images, image_dict)\n",
    "\n",
    "                output_dir = os.path.join('matches', patient)\n",
    "\n",
    "                if similarity_results:\n",
    "\n",
    "                    for i, match in enumerate(similarity_results, 1):\n",
    "                        match_dir = os.path.join(output_dir, f'match{i}')\n",
    "\n",
    "                        os.makedirs(match_dir, exist_ok = True)\n",
    "\n",
    "                        _, axs = plt.subplots(1, 3)\n",
    "\n",
    "                        for i, (name, img) in enumerate(match.items()):\n",
    "\n",
    "                            axs[i].imshow(img)\n",
    "\n",
    "                            cv2.imwrite(os.path.join(match_dir, name.replace('tif', 'jpg')),\n",
    "                                        img,\n",
    "                                        [int(cv2.IMWRITE_JPEG_QUALITY), 50])\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                else:\n",
    "                    g = make_new_image_groups(patient_path) # noah's algo\n",
    "                    \n",
    "                    if len(g) > 0:\n",
    "                        for i, match in enumerate(g, 1):\n",
    "                            score = match[-1]\n",
    "                            names = match[:-1]\n",
    "\n",
    "                            # similarity threshold\n",
    "                            if score > 0.1:\n",
    "                                match_dir = os.path.join(output_dir, f'match{i}')\n",
    "\n",
    "                                os.makedirs(match_dir, exist_ok = True)\n",
    "                            \n",
    "                                _, axs = plt.subplots(1, 3)\n",
    "\n",
    "                                for i, name in enumerate(names):\n",
    "\n",
    "                                    img = raw_images[name]\n",
    "\n",
    "                                    axs[i].imshow(img)\n",
    "\n",
    "                                    cv2.imwrite(os.path.join(match_dir, name.replace('tif', 'jpg')),\n",
    "                                                img,\n",
    "                                                [int(cv2.IMWRITE_JPEG_QUALITY), 50])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Processed {patient}\")\n",
    "            print(\"------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Example usage - change folder as needed\n",
    "folder_path = 'processed_images'\n",
    "\n",
    "process_all_patients(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
